{
    "model": "H:\\Models\\lmstudio-community\\Qwen3-30B-A3B-GGUF\\Qwen3-30B-A3B-Q8_0.gguf",
    "threads": "4",
    "gpulayers": "0",
    "contextsize": "131072",
    "tensor_split": "",
    "flashattention": false,
    "usecublas": false,
    "usevulkan": false,
    "useclblast": false,
    "usecpu": false,
    "ropeconfig": "",
    "blasbatchsize": "512",
    "blasthreads": "8",
    "lora": "",
    "noshift": false,
    "nofastforward": false,
    "usemmap": false,
    "usemlock": true,
    "noavx2": false,
    "failsafe": false,
    "debugmode": false,
    "highpriority": false,
    "foreground": false,
    "quiet": false,
    "ssl": false,
    "nocertify": false,
    "password": "",
    "ignoremissing": false,
    "quantkv": "",
    "smartcontext": false,
    "nobostoken": false,
    "maxrequestsize": "1024",
    "temperature": "",
    "min_p": "",
    "seed": "",
    "n_predict": "32000",
    "ignore_eos": true
} 